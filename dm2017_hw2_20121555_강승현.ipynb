{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "SUMMARY_DIR = './mnist'\n",
    "\n",
    "MNIST = input_data.read_data_sets(\"./MNIST_data\",one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "def get_train_batch(batch_size, fake_data=False):\n",
    "\n",
    "    a = batch_size/128\n",
    "    b = batch_size%128\n",
    "    \n",
    "    #shuffle the data \n",
    "   #perm = numpy.arange(self._num_examples) \n",
    "   #numpy.random.shuffle(perm) \n",
    "        \n",
    "    for i in range(a):\n",
    "        batch_xs, batch_ys =MNIST.train.next_batch(128)\n",
    "    \n",
    "    for i in range(b):\n",
    "        batch_xs, batch_ys =MNIST.train.next_batch(b)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('input') as scope:\n",
    "    X= tf.placeholder(tf.float32, [None, 784], name = 'image')\n",
    "    y= tf.placeholder(tf.float32, [None, 10], name = 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('layer1') as scope:\n",
    "    W1 = tf.get_variable(\"W\", shape = [784,512], initializer = tf.contrib.layers.xavier_initializer())\n",
    "   # W1 = np.random.randn(784, 512)/ np.sqrt(784)\n",
    "    b1 = tf.Variable(tf.random_normal([512]))\n",
    "    L1 = tf.nn.relu(tf.add(tf.matmul(X, W1),b1))\n",
    "    \n",
    "    tf.summary.histogram(\"X\",X)\n",
    "    tf.summary.histogram(\"weights\", W1)\n",
    "    tf.summary.histogram(\"bias\", b1)\n",
    "    tf.summary.histogram(\"layer\",L1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('layer2') as scope:\n",
    "    W2 = tf.get_variable(\"W\", shape = [512,512], initializer = tf.contrib.layers.xavier_initializer())\n",
    "   # W1 = np.random.randn(784, 512)/ np.sqrt(784)\n",
    "    b2 = tf.Variable(tf.random_normal([512]))\n",
    "    L2 = tf.nn.relu(tf.add(tf.matmul(L1, W2),b2))\n",
    "    \n",
    "    \n",
    "    #tf.summary.histogram(\"weights\", W1)\n",
    "    tf.summary.histogram(\"weights\", W2)\n",
    "    tf.summary.histogram(\"bias\", b2)\n",
    "    tf.summary.histogram(\"layer\",L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('layer3') as scope:\n",
    "    W3 = tf.get_variable(\"W\", shape=[512, 10], initializer = tf.contrib.layers.xavier_initializer())\n",
    "    b3 = tf.Variable(tf.random_normal([10]))\n",
    "    y_ = tf.add(tf.matmul(L2, W3), b3)\n",
    "    \n",
    "    tf.summary.histogram(\"weights\", W3)\n",
    "    tf.summary.histogram(\"bias\", b3)\n",
    "    tf.summary.histogram(\"logits\", y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = y_, labels = y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate).minimize(loss)\n",
    "tf.summary.scalar(\"loss\", loss)\n",
    "\n",
    "summary = tf.summary.merge_all()\n",
    "\n",
    "global_step =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    writer = tf.summary.FileWriter(SUMMARY_DIR, sess.graph)\n",
    "    for epoch in range(training_epochs):\n",
    "        total_batch = int(MNIST.train.num_examples / batch_size)\n",
    "        avg_loss =0\n",
    "        \n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys =MNIST.train.next_batch(batch_size)\n",
    "            #get_train_batch(batch_size)\n",
    "            feed_dict = {X: batch_xs, y: batch_ys}\n",
    "            s, l,  _ = sess.run([summary, loss, optimizer], feed_dict = feed_dict)\n",
    "            writer.add_summary(s, global_step=global_step)\n",
    "            global_step +=1\n",
    "            avg_loss+= l\n",
    "        print('Epoch:','%02d'%(epoch + 1), 'loss=','{:.6f}'.format(avg_loss/total_batch))\n",
    "        \n",
    "    correct_prediction = tf.equal(tf.argmax(y_, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    acc = sess.run(accuracy,feed_dict = {X:MNIST.test.images, y: MNIST.test.labels})\n",
    "    print('Test accuracy!:', acc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
